This mini-course will provide a gentle introduction to data science and applied machine learning. If you're a developer, analyst, manager, or aspiring data scientist looking learn more about data science, then you're in the right place.  
## Bird's Eye View
First, let’s start with the “80/20” of data science…

Generally speaking, we can break down applied machine learning into the following chunks:

What Goes Into a Successful Model

This data science primer will cover exploratory analysis, data cleaning, feature engineering, algorithm selection, and model training. As you can see, those chunks make up 80% of the pie. They also set the foundation for more advanced techniques.

## Exploratory Analysis  
There’s a big challenge in data science called “Tactical Hell.” This is actually a term from startups, and it’s when you have too many tactics to choose from:

Should you develop your product more? Invest in marketing? Hire an accountant? Etc.

In many ways, training a ML model is like growing a startup. You also have too many tactics to choose from:

Should you clean your data more? Engineer features? Test new algorithms? Etc.

There’s a lot of trial and error, so how do you avoid chasing dead ends? The answer is “Exploratory Analysis.”

## Data Cleaning
Proper data cleaning is the “secret” sauce behind machine learning… Well, it’s not really a “secret”… It’s just a bit boring, so no one really talks about it. But the truth is:

Better data beats fancier algorithms…

(Even if you forget everything else from this primer, please remember this point)

Garbage in = Garbage out... Plain and Simple! If you have a clean dataset, even simple algorithms can learn impressive insights from it!

## Feature Engineering
In a nutshell, “feature engineering” is creating new model input features from your existing ones.

That doesn’t sounds like much… Yet Andrew Ng, former head of Baidu AI and Google Brain, said:

“Coming up with features is difficult, time-consuming, requires expert knowledge.
‘Applied machine learning’ is basically feature engineering.”

Wow! No pressure, right?

So why is it so difficult and time-consuming?

To start, feature engineering is very open-ended. There are literally infinite options for new features to create. Plus, you’ll need domain knowledge to add informative features instead of more noise.

## Algorithm Selection
In applied machine learning, individual algorithms should be swapped in and out depending on which performs best for the problem and the dataset.

Therefore, we will focus on intuition and practical benefits over math and theory.

We have two main goals:

To explain powerful mechanisms in modern ML.
To introduce several algorithms that use those mechanisms.

## Model Training
It might seem like it took a while to get here, but data scientists actually do spend most their time on the earlier steps:

Exploring the data.
Cleaning the data.
Engineering new features.
Again, that’s because better data beats fancier algorithms.

Now you'll learn how to maximize model performance while safeguarding against overfitting. Plus, you'll learn how to automatically find the best parameters for each algorithm.

[Source](https://elitedatascience.com/primer)
